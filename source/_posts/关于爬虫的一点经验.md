---
abbrlink: 4b69a11a
date: 2019-10-27
description: 关于爬虫的一些小总结
---
突然有这么一天，我的一位同学找到了我，问我做不做爬虫的外包，是一位已经毕业的师兄。

他说他准备开奶茶店，因此想了解整个广州地区的奶茶店分布，以及奶茶店销量与地点的关系，借此来找到合适的地点开奶茶店。

当时也是年轻，对价格没太多了解，最终是以 300 块的价格成交了，但是还是学到不少东西的。

我们选择的爬虫对象就是我们的外卖平台：“饿了吗”。通过外卖的销量，也能一定程度地反映出奶茶店的销量。

首先让我们理清一下思路。

爬虫大体上分为五个部分：爬取、存储、解析、代码优化、防反爬

我接下来会一一解释其中如何操作。

首先一个大体的爬取思路是：

模拟登录

获取奶茶店铺总数

一页页去找商家

根据 id 去获取商家地址

爬取
首先是模拟登录部分
首先先输入手机号码，然后让饿了吗发送手机验证码

这个时候有两种情况，有图片验证码（也就是让你识别字母），或者是没有图片验证码，会直接发送手机验证码

有图片验证码的情况下怎么处理呢？我们可以将验证码的图片先转为二进制，再将二进制转为 png 格式的图片，下载到本地。然后用电脑自带的图片播放器打开，进行人工识别并手动输入验证码。

查看手机，输入手机短信上的验证码。

模拟登录部分就是这样了。

获取奶茶店铺总数
为什么要获取奶茶店铺总数呢？

因为你第三步一页页去找商家，其实是有一个最大数量的。如果不获取奶茶店铺总数，爬虫就会去找一些没有信息的页面。

用 chrome 获取接口，post 即可

一页页去找商家
观察饿了吗的页面，可以看到饿了吗每个页面会显示 8 个商家

所以我们设置每次获取 8 个商家，直到超过奶茶店铺总数

获取商家地址
商家的地址有点特别，是要点开具体的商家，才能看到地址

而饿了吗后台给每个商家分配了一个单独的商家 id

这个 id 去哪里获取呢？仔细分析后，可以看到我们在一页页找商家的时候，获取商家经纬度的时候，同时也可以获取到商家的 id

所以我们前面存储商家的 id，用来获取商家地址

最后把商家 id 删除即可

解析
解析部分没什么好讲的，主要就是将页面信息或者将服务器返回的数据，提取出自己想要的。

一般来说，静态页面用 BeautifulSoup 这个库来解析。动态页面，用 json 这个库，将数据转化为 json 格式。

另外，还有正则化，css 解析器等等。

存储
存储过程中有一个很大的问题，就是两个很近的地方，可能获取的商家信息基本都是重复的。所以去重是一个问题。

另外就是，数据其实是存储在内存里面的，万一爬取的数据太多，内存不够放怎么办？

去重
去重的话，我们可以将数据先转为 pandas 的 DataFrame，然后 DataFrame 有一个内置函数可以去重。

数据库
内存的大小是有限的。我们可以这样处理，在本地安装 mysql，然后每次爬取一个地址，就将那里的数据存储在 mysql 数据库里面，然后再将内存里面的数据释放掉。

因为有内存回收机制，这样内存绝对够用。

当然我这里没有用过数据库。

代码优化
我在爬取过程中发现，爬取速度异常的慢 QAQ

提供几种加速的思路。

多线程
线程是操作系统能够进行运算调度的最小单位。多线程相当于有多个爬虫同时爬取。但是一定要注意，一定要防止堵塞，也就是要异步执行，下面几种相同。

多进程
进程在线程之上。我在代码中就是使用了多进程。还挺方便的，毕竟 python 有多进程和多线程的库，可以查一下官方文档即可使用。

分布式
分布式我没接触过，但是分布式可以更加快的加速爬取的速度。

分布式通俗的讲，就是多台电脑一起爬取。可以将一个爬取任务，细分为多个子任务。

每个电脑完成自己的任务后，再将自己的那部分数据上传，最终整合起来。

线程<进程<电脑，所以速度上多线程<多进程<分布式。

防反爬
我在爬取的时候，深受反爬制度的打击。

好一点的，封 ip。差一点的，直接把账号给封了。最严重的是，有一天刚好不是很幸运，加密手段换了。当然不是因为我才换得，是刚好他们公司打算换，所以就只能换一种方式来爬取了。

解决方式：

封 ip 的话，可以使用代理池。见过身边有同学做过代理池，也用过，不过原理不是很清楚。

获取 cookie。一般浏览器是怎么样知道你是登录的呢，是通过 cookie 或者 token。

一般是，当你登录的时候，登录服务器会将一段口令，当然生成口令的算法只有别人才知道。

它会将口令存储在登陆服务器上，同时也会发到你的电脑或者手机上。当你尝试获取信息时，服务器就会找他自己服务器里面有没有这个口令，如果有代表已经登录。

模拟浏览器行为。怎么说呢？有一个库叫做 selenium，它可以控制浏览器行为，比如你在电脑上输入代码，让浏览器打开某个网址。那么浏览器真的可以打开那个网址。

也可以模拟上划滚动等等行为。所以这种方法也是没那么容易被封的，因为他跟用户的行为是相同的，就是爬取速度比较慢就是了，但是是自动化的。

原文以及代码见:[https://github.com/xilou31/eLeMa_Crawler](https://github.com/xilou31/eLeMa_Crawler)
